---
bibliography: ChangepointSampling.bib
csl: ecology-letters.csl
editor_options:
  chunk_output_type: console
fontsize: 12pt
geometry: margin=1in
header-includes: \usepackage{float} \usepackage{lineno} \usepackage{setspace}\doublespacing
  \usepackage[round]{natbib} \bibpunct[; ]{(}{)}{,}{a}{}{,} \usepackage{color} \usepackage{totcount}
  \newtotcounter{citenum} \def\oldcite{} \let\oldcite=\bibcite \def\bibcite{\stepcounter{citenum}\oldcite}
  \renewcommand{\thepage}{S\arabic{page}}
  \renewcommand{\thesection}{Appendix S\arabic{section}} \renewcommand{\thetable}{S\arabic{table}}
  \renewcommand{\thefigure}{S\arabic{figure}}
  \usepackage{amsmath}
  \renewcommand{\theequation}{S\arabic{equation}} \floatplacement{figure}{H}
output:
  pdf_document:
    fig_caption: yes
    keep_tex: yes
    number_sections: no
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = dirname(getwd()))
```




\begin{center}
\textbf{\Large Supplementary Material for: Sampling requirements and approaches to detect ecosystem shifts}
\vspace{7 mm}
	
\textsc{Rosalie Bruel$^{1}$ and Easton R. White$^{2}$}
\vspace{5 mm}

\normalsize{\indent $^{1}$Rubenstein Ecosystem Science Laboratory, University of Vermont, VT 05405, USA \\ $^{2}$Department of Biology, University of Vermont, VT 05405, USA}
\end{center}

\vspace{2 mm}

\tableofcontents

\vspace{1cm}

Data and code for all the figures can be found at (https://github.com/rosalieb/temporal-sampling). All the analyses were run in R [@RCoreTeam2019].


\clearpage


# Additional methods

We first detect the "true" changepoint of a full length time series with the function _e.divisive_ in the R package _ecp_ [@James2019]. We focus on the changepoint with the largest magnitude, although this package allows detection of further changepoints as well (Fig. \ref{fig:case_study_other_changepoints}). We then subsample the full time series [@White2020] with different numbers of subsamples and different sampling approaches. For each sampling approach, we wrote a custom function:

- sample_random(): sample first and last sample, in addition of n-2 random samples in between (n = maximum number of sample, chosen by the user),  
- sample_regular(): sample first and last sample, in addition of n-2 evenly spaced samples in between (n = maximum number of samples, chosen by the user), and  
- sample_iterative(): sample first and last sample as well as 3 evenly spaced samples in between (3 is the default but can be modified), in order to initiate the changepoint detection. Upon detection of the changepoint on this 5 samples time series, a new sample is added between the changepoint and the previous sample, to narrow down the real changepoint. Detection of changepoint and addition of sample is repeated, until it was narrowed down to two consecutive samples, or n (maximum number of samples, chosen by the user) was reached, whichever comes first.  
  
The subsampled time series are then compared to the full time series to assess the effectiveness of each subsampling approach.

Each function works with two types of input: vector and matrix. If the input is a matrix, the user must change the default argument *is_vector* to *FALSE*. The matrix is then transformed to independent vectors using Detrended Correspondence Analysis [@Hill1980], and a single axis on which changepoint analysis is run is chosen with the argument *DCA_axis* (default to 1, for first component). Component scores are returned by the function. A user can edit the function to use another ordination method (e.g., principal component analysis).


# Parameter sensitivity

We investigated how different parameters change the power of the analysis, and found that autocorrelation at lag-1 (phi) had little impact on the power of the analysis amplitude of the shift was the most important determinant of the power of the analysis. For null standard deviation, the analysis performed well independently of the shift size or autocorrelation. When standard deviation increased, the power of the analysis was higher for null autocorrelation (Fig. \ref{fig:parameter_sensitivity_plot}).

```{r parameter_sensitivity,message=F,warning=F,echo=F,eval=F,cache=F}
# Build 1x3 plot with sigma vs phi with color equal to distance to changepoint, power, or min time. The three panel plots would represent different shift size values

source('R/sampling_regular.R')
source('R/sampling_random.R')
source('R/build_time_series.R')
source('R/calc_min_time2.R')
require(tidyverse)

number_sims <- 10
# Find minimum time for different parameter combos

sigma_vec = seq(0.01,0.3,0.02)
phi_vec = seq(-0.8,0.8,0.1)
shift_size_vec = c(0.1,0.4,0.8)

output_theory_approach <- data.frame(expand.grid(sigma_vec,phi_vec,shift_size_vec))
names(output_theory_approach) <- c('sigma_vec', 'phi_vec', 'shift_size_vec')
output_theory_approach$power = 0

#params <- tibble(shift_time = sample(30:70,max(simulation_number),replace = T))

shift_time = sample(30:70,number_sims,replace=T) # Keep shift times constant for each param combo
                  
# Run through params
for (i in 1:nrow(output_theory_approach)){

# Build XX number of time series
params <- list(sigma=rep(output_theory_approach$sigma_vec[i],number_sims),phi=rep(output_theory_approach$phi_vec[i],number_sims),shift_size=rep(output_theory_approach$shift_size_vec[i],number_sims),shift_time = shift_time)

time_series <- params %>%
  pmap(build_time_series) %>%
  map_dbl(function(df) sample_regular(df,20)$changepoint) 

power <- sum(abs(time_series-shift_time)<5)/number_sims

#print(i)
output_theory_approach$power[i] <- power
}



write.csv(x = output_theory_approach,file = 'Output/parameter_sensitivity.csv',quote = FALSE )

require(ggplot2)
require(viridis)
ggplot(aes(x=phi_vec,y=sigma_vec,fill=power),data=output_theory_approach) + geom_tile() +
   scale_fill_viridis(discrete=FALSE,begin = 0.1,end=0.9) +
  facet_wrap(~shift_size_vec) +
   labs(fill='Statistical power') +
   xlab("Lag-1 autocorrelation (phi)") +
   ylab("Standard deviation (sigma)") +
   theme_classic(base_size = 14, base_family = "")

```

```{r parameter_sensitivity_plot,echo=F,message=F,warnings=F,fig.height=4,fig.cap='Regular sampling statistical power (fraction of 100 simulations which detecting a changepoint within five time points of the true changepoint) for different levels of standard deviation, lag-1 autocorrelation, and shift size.\\label{fig:parameter_sensitivity_plot}'}
output_theory_approach <- read.csv(file = 'Output/parameter_sensitivity.csv')

require(ggplot2)
require(viridis)
ggplot(aes(x=phi_vec,y=sigma_vec,fill=power),data=output_theory_approach) + geom_tile() +
   scale_fill_viridis(discrete=FALSE,begin = 0.1,end=0.9) +
  facet_wrap(~shift_size_vec) + 
   theme_classic(base_size = 14, base_family = "")+
  theme(plot.subtitle = element_text(hjust = 0.5)) +
   labs(fill='Power',subtitle = 'Shift size') +
   xlab("Lag-1 autocorrelation (phi)") +
   ylab("Standard deviation (sigma)")
```


# Minimum time for other sampling approaches

## Random sampling

```{r simulation_min_time_random,message=F,warning=F,echo=F,eval=F,cache=T}

source('R/sampling_random.R')
source('R/build_time_series.R')
source('R/updated_param_sensitivity.R')
source('R/calc_min_time2.R')
require(tidyverse)

# Sigma results
sigma_vec = seq(0.01,0.4,0.025)
min_time  = rep(0,times=length(sigma_vec))
sigma_output <- data.frame(sigma_vec,min_time)

for (param_num in 1:nrow(sigma_output)){
  sigma_output$min_time[param_num] <- calc_min_time('sigma',sigma_output$sigma_vec[param_num],'random')
  #print(sigma_output)
}

write.csv(x = sigma_output,file = 'Output/theoretical_results_random_sigma.csv',quote=FALSE)

# Phi results

phi_vec = seq(-0.8,0.8,0.05)
min_time  = rep(0,times=length(phi_vec))
phi_output <- data.frame(phi_vec,min_time)

for (param_num in 1:nrow(phi_output)){
  phi_output$min_time[param_num] <- calc_min_time('phi',phi_output$phi_vec[param_num],'random')
  #print(phi_output)
}

write.csv(x = phi_output,file = 'Output/theoretical_results_random_phi.csv',quote=FALSE)


# Shift size

shift_size_vec = rev(seq(0.1,0.9,0.05))
min_time  = rep(0,times=length(shift_size_vec))
shift_size_output <- data.frame(shift_size_vec,min_time)

for (param_num in 1:nrow(shift_size_output)){
  shift_size_output$min_time[param_num] <- calc_min_time('shift_size',shift_size_output$shift_size_vec[param_num],'random')
  #print(shift_size_output)
}

write.csv(x = shift_size_output,file = 'Output/theoretical_results_random_shift_size.csv',quote=FALSE)


```



```{r simulation_min_time_plot_random, fig.width = 7.2, fig.height= 3, fig.cap='Minimum number of samples required for 0.8 statistical power given different levels of (a) temporal variability ($\\sigma$), (b) temporal autocorrelation ($\\phi$), and (c) shift size. Random sampling was used with the default parameters are $\\sigma = 0.53$, $\\phi = 0.404$, and a shift size $=0.81$ to match the case study. The exact timing of the true changepoint varied for each simulation between time steps 30 and 70. Each vertical line indicates the respective parameter calculated from the case study time series. \\label{fig:simulation_min_time_random}',message=F,warning=F,echo=F,eval=T}
require(ggplot2)
require(dplyr)
require(stickylabeller)
par(mfrow=c(1,3))

sigma <- read.csv('Output/theoretical_results_random_sigma.csv',header=TRUE)

phi <- read.csv('Output/theoretical_results_random_phi.csv',header=TRUE)

shift_size <- read.csv('Output/theoretical_results_random_shift_size.csv',header=TRUE)


# Melt the 3 dataset to be able to use facet_wrap()
colnames(sigma) <- colnames(phi) <- colnames(shift_size) <- c("X", "Param", "min_time")
simulation_all <- 
  rbind(cbind("Parameter" = rep("Standard deviation", nrow(sigma)), sigma),
        cbind("Parameter" = rep("Autocorrelation at lag-1", nrow(phi)), phi),
        cbind("Parameter" = rep("Normalized amplitude of shift", nrow(shift_size)), shift_size))
# param_vr <- data.frame("Parameter" = unique(simulation_all$Parameter),
#                        "value" = c(ar_vr, cv_vr, shift_vr))

p1 <- 
  ggplot(simulation_all %>% filter(Parameter == unique(simulation_all$Parameter)[1]), aes(Param, min_time)) +
  geom_point() +
  geom_line() +
  geom_vline(xintercept=0.05, lty=2) + 
  facet_wrap(~Parameter, scales="free_x", 
             labeller = label_glue('a. {Parameter}')) +
  ylim(10,52) +
  labs(x=c("sigma"), y= "Minimum number of samples required") + 
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        strip.background = element_rect(colour="transparent", fill="transparent"),
        strip.text.x = element_text(angle = 0, hjust = 0))
p2 <- ggplot(simulation_all %>% filter(Parameter == unique(simulation_all$Parameter)[2]), aes(Param, min_time)) +
  geom_point() +
  geom_line() +
  geom_vline(xintercept = 0.404, lty=2) +
  facet_wrap(~Parameter, scales="free_x", 
             labeller = label_glue('b. {Parameter}')) +
  ylim(10,52) +
  labs(x="phi", y= "") + 
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        strip.background = element_rect(colour="transparent", fill="transparent"),
        strip.text.x = element_text(angle = 0, hjust = 0))
p3 <- ggplot(simulation_all %>% filter(Parameter == unique(simulation_all$Parameter)[3]), aes(Param, min_time))  +
  geom_point() +
  geom_line() + 
  geom_vline(xintercept = 0.81, lty=2) +
  facet_wrap(~Parameter, scales="free_x", 
             labeller = label_glue('c. {Parameter}')) +
  ylim(10,52) +
  labs(x="shift size", y= "") + 
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        strip.background = element_rect(colour="transparent", fill="transparent"),
        strip.text.x = element_text(angle = 0, hjust = 0))


# Remove the y-axis for the 2nd plot - p2 then merge 2 plots
cowplot::plot_grid(p1 + theme(plot.margin = unit(c(0.15, 0.1, 0.15, 0.15), "cm")), 
                   p2 + 
                     theme(plot.margin = unit(c(0, 0.1, 0, 0), "cm"),
                           axis.text.y = element_blank(),
                           axis.line.y = element_blank(),
                           axis.title.y= element_blank(),
                           axis.ticks.y= element_blank()),
                   p3 + 
                     theme(plot.margin = unit(c(0, 0.1, 0, 0), "cm"),
                           axis.text.y = element_blank(),
                           axis.line.y = element_blank(),
                           axis.title.y= element_blank(),
                           axis.ticks.y= element_blank()),
                   nrow = 1,
                   rel_widths = c(1.2, 1,1),
                   align = 'h', axis = 'tb')

```




## Iterative sampling

```{r simulation_min_time_iterative,message=F,warning=F,echo=F,eval=F,cache=T}


source('R/sampling_iterative.R')
source('R/build_time_series.R')
source('R/updated_param_sensitivity.R')
source('R/calc_min_time2.R')
require(tidyverse)

# Sigma results
sigma_vec = seq(0.01,0.4,0.025)
min_time  = rep(0,times=length(sigma_vec))
sigma_output <- data.frame(sigma_vec,min_time)

for (param_num in 11:nrow(sigma_output)){
  sigma_output$min_time[param_num] <- calc_min_time('sigma',sigma_output$sigma_vec[param_num],'iterative')
  print(sigma_output)
}

write.csv(x = sigma_output,file = 'Output/theoretical_results_iterative_sigma.csv',quote=FALSE)

# Phi results

phi_vec = seq(-0.8,0.8,0.05)
min_time  = rep(0,times=length(phi_vec))
phi_output <- data.frame(phi_vec,min_time)

for (param_num in 1:nrow(phi_output)){
  phi_output$min_time[param_num] <- calc_min_time('phi',phi_output$phi_vec[param_num],'iterative')
  #print(phi_output)
}

write.csv(x = phi_output,file = 'Output/theoretical_results_iterative_phi.csv',quote=FALSE)


# Shift size

shift_size_vec = rev(seq(0.1,0.9,0.05))
min_time  = rep(0,times=length(shift_size_vec))
shift_size_output <- data.frame(shift_size_vec,min_time)

for (param_num in 1:nrow(shift_size_output)){
  shift_size_output$min_time[param_num] <- calc_min_time('shift_size',shift_size_output$shift_size_vec[param_num],'iterative')
  #print(shift_size_output)
}

write.csv(x = shift_size_output,file = 'Output/theoretical_results_iterative_shift_size.csv',quote=FALSE)


```



```{r simulation_min_time_plot_iterative, fig.width = 7.2, fig.height= 3, fig.cap='Minimum number of samples required for 0.8 statistical power given different levels of (a) temporal variability ($\\sigma$), (b) temporal autocorrelation ($\\phi$), and (c) shift size. Iterative sampling was used with the default parameters are $\\sigma = 0.53$, $\\phi = 0.404$, and a shift size $=0.81$ to match the case study. The exact timing of the true changepoint varied for each simulation between time steps 30 and 70. Each vertical line indicates the respective parameter calculated from the case study time series. \\label{fig:simulation_min_time}',message=F,warning=F,echo=F,eval=T}

par(mfrow=c(1,3))

sigma <- read.csv('Output/theoretical_results_iterative_sigma.csv',header=TRUE)

phi <- read.csv('Output/theoretical_results_iterative_phi.csv',header=TRUE)

shift_size <- read.csv('Output/theoretical_results_iterative_shift_size.csv',header=TRUE)


# Melt the 3 dataset to be able to use facet_wrap()
colnames(sigma) <- colnames(phi) <- colnames(shift_size) <- c("X", "Param", "min_time")
simulation_all <- 
  rbind(cbind("Parameter" = rep("Standard deviation", nrow(sigma)), sigma),
        cbind("Parameter" = rep("Autocorrelation at lag-1", nrow(phi)), phi),
        cbind("Parameter" = rep("Normalized amplitude of shift", nrow(shift_size)), shift_size))
# param_vr <- data.frame("Parameter" = unique(simulation_all$Parameter),
#                        "value" = c(ar_vr, cv_vr, shift_vr))

p1 <- 
  ggplot(simulation_all %>% filter(Parameter == unique(simulation_all$Parameter)[1]), aes(Param, min_time)) +
  geom_point() +
  geom_line() +
  geom_vline(xintercept=0.05, lty=2) + 
  facet_wrap(~Parameter, scales="free_x", 
             labeller = label_glue('a. {Parameter}')) +
  ylim(10,50) +
  labs(x=c("sigma"), y= "Minimum number of samples required") + 
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        strip.background = element_rect(colour="transparent", fill="transparent"),
        strip.text.x = element_text(angle = 0, hjust = 0))
p2 <- ggplot(simulation_all %>% filter(Parameter == unique(simulation_all$Parameter)[2]), aes(Param, min_time)) +
  geom_point() +
  geom_line() +
  geom_vline(xintercept = 0.404, lty=2) +
  facet_wrap(~Parameter, scales="free_x", 
             labeller = label_glue('b. {Parameter}')) +
  ylim(10,50) +
  labs(x="phi", y= "") + 
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        strip.background = element_rect(colour="transparent", fill="transparent"),
        strip.text.x = element_text(angle = 0, hjust = 0))
p3 <- ggplot(simulation_all %>% filter(Parameter == unique(simulation_all$Parameter)[3]), aes(Param, min_time))  +
  geom_point() +
  geom_line() + 
  geom_vline(xintercept = 0.81, lty=2) +
  facet_wrap(~Parameter, scales="free_x", 
             labeller = label_glue('c. {Parameter}')) +
  ylim(10,50) +
  labs(x="shift size", y= "") + 
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        strip.background = element_rect(colour="transparent", fill="transparent"),
        strip.text.x = element_text(angle = 0, hjust = 0))


# Remove the y-axis for the 2nd plot - p2 then merge 2 plots
cowplot::plot_grid(p1 + theme(plot.margin = unit(c(0.15, 0.1, 0.15, 0.15), "cm")), 
                   p2 + 
                     theme(plot.margin = unit(c(0, 0.1, 0, 0), "cm"),
                           axis.text.y = element_blank(),
                           axis.line.y = element_blank(),
                           axis.title.y= element_blank(),
                           axis.ticks.y= element_blank()),
                   p3 + 
                     theme(plot.margin = unit(c(0, 0.1, 0, 0), "cm"),
                           axis.text.y = element_blank(),
                           axis.line.y = element_blank(),
                           axis.title.y= element_blank(),
                           axis.ticks.y= element_blank()),
                   nrow = 1,
                   rel_widths = c(1.2, 1,1),
                   align = 'h', axis = 'tb')

```





# Detecting further changepoints

The initial study found 3 changepoints on the main axis, in 1926/1928, 1946/1948 and 1983/1988 [@Bruel2018]. We focused our analysis on the main changepoint, but the code also allows to target further changepoints, using the argument *c*. *c* is a numeric value indicating the maximum number of changepoints to find (Fig. \ref{fig:case_study_other_changepoints}).

The iterative method requires less subsamples overall to find the real changepoints (Fig. \ref{fig:case_study_other_changepoints}, 3rd column). Note that if the initial number of samples (controlled with the argument *n2* in the code) is at the default 5, the code struggles to rank appropriately the changepoints, resulting in a changepoint being found, but not the overall "true" second  (e.g., Fig. \ref{fig:case_study_other_changepoints}b, 3rd column), or "true" third. For a time-series, we recommend users examine the p-values returned by the *e.divisive* function, embedded in the function *sample_iterative* output. If the first few changepoints have close, low p-values, it may be useful to add another subsample further away from the presumed changepoint. This avoids the iterative algorithm mistakenly converging on the wrong changepoint. An alternative is to initiate the subsampling with an higher number of samples, e.g., 7 subsamples.

```{r case study read data output, include=FALSE}
myoutput <- read.table(paste0(getwd(),"/Output/output_changepoint_varese.txt"))
myoutput$method_f <- factor(myoutput$method, levels=c('Random', 'Regular', 'Iterative'))

```


```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width = 7.2, fig.height= 8,fig.cap='Distance to true (a) first changepoint (largest magnitude), (b) second changepoint, and (c) third changepoint for total number of samples analyzed, following random sampling, regular sampling, and iterative sampling. Total number of samples was set between 5 and 30, out of the 74 initial time series.  \\label{fig:case_study_other_changepoints}'}
library(ggplot2)
library(gridExtra)
p1 <- ggplot(myoutput[myoutput$target_cpt==1,], aes(final_n,diff_real, pch=factor(n2_init))) + 
  geom_hline(aes(yintercept=0), col=adjustcolor("black", alpha.f = .4)) + 
  geom_point(alpha = .3) +
  facet_wrap(~method_f) + theme_bw() +
  labs(title="a. First changepoint",x="", y="Distance to real changepoint") +
  theme(legend.position = c(0.93, 0.6),
        legend.background = element_rect(fill = "#ffffffaa", colour = NA),
        legend.title=element_text(size=7), 
        legend.text=element_text(size=8)) +
  guides(pch=guide_legend(title="Initial number\nof sample"))
p2 <- ggplot(myoutput[myoutput$target_cpt==2,], aes(final_n,diff_real, pch=factor(n2_init))) + 
  geom_hline(aes(yintercept=0), col=adjustcolor("black", alpha.f = .4)) + 
  geom_point(alpha = .3) +
  facet_wrap(~method_f) + theme_bw() +
  labs(title="b. Second changepoint",x="", y="Distance to real changepoint") +
  theme(legend.position = c(0.93, 0.6),
        legend.background = element_rect(fill = "#ffffffaa", colour = NA),
        legend.title=element_text(size=7), 
        legend.text=element_text(size=8)) +
  guides(pch=guide_legend(title="Initial number\nof sample"))
p3 <- ggplot(myoutput[myoutput$target_cpt==3,], aes(final_n,diff_real, pch=factor(n2_init))) + 
  geom_hline(aes(yintercept=0), col=adjustcolor("black", alpha.f = .4)) + 
  geom_point(alpha = .3) +
  facet_wrap(~method_f) + theme_bw() +
  labs(title="c. Third changepoint",x="", y="Distance to real changepoint") +
  theme(legend.position = c(0.93, 0.6),
        legend.background = element_rect(fill = "#ffffffaa", colour = NA),
        legend.title=element_text(size=7), 
        legend.text=element_text(size=8)) +
  guides(pch=guide_legend(title="Initial number\nof sample"))
grid.arrange(p1,p2,p3,nrow=3)
```


# Case study: Changepoint detection of abundance time series

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}
# Investigating change in species average biomass
# Read code
source('R/sampling_regular.R')
# Read data
getpath4data <- function() {
  if(Sys.getenv("USER")=="Rosalie") return("/Volumes/-/Script R/Data-off-GitHub/temporal-sampling/")
  if(Sys.getenv("USER")=="eastonwhite") return("~/Desktop/Research/soil-temporal-sampling/")
  if(Sys.getenv("USER")!="Rosalie"|Sys.getenv("USER")!="put here your USER") stop("You need to get the data and define their location.")
}
vr <- read.delim(paste0(getpath4data(),"VAR10-10-clado.txt"))
vr_count <- data.frame(Year=vr[,1], Biomass=rowSums(vr[,-1]))
cpvar_count <- sample_regular(vr_count[,2], nrow(vr_count), input_vector = T, messages = F)

```

As another example of our approach, we we re-used the community dataset from Lake Varese, but this time, looked at the total number of individuals per gram of sediment in each subsamples. Thus, this is a univariate time series as opposed to the community-level data used in the main text. The full time series show a changepoint in `r paste(vr_count$Year[cpvar_count$changepoint], vr_count$Year[cpvar_count$changepoint-1], sep="/")`. We used the three changepoint method to estimate changepoint on the vector, and found that the iterative method, with an initial number of 5 regularly-spaced subsamples, performed best (Fig. \ref{fig:case_study_number_sample_biomass}).


```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.width = 4, fig.height= 3, fig.cap='Number of individuals per gram of sediment, infered from Cladocera remains for the 74 subsamples of the Lake Varese sediment core. Vertical grey band indicates the "true" changepoint.   \\label{fig:case_study_biomass_per_year}'}
# plot
ggplot(vr_count, aes(Year, Biomass)) + 
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        strip.background = element_rect(colour="transparent", fill="transparent")) +
           geom_rect(mapping=aes(xmin=vr_count$Year[cpvar_count$changepoint-1], xmax=vr_count$Year[cpvar_count$changepoint], ymin=0, ymax=max(vr_count)), alpha=0.05, fill="grey") + 
  geom_line() +
  labs(y="Number of individuals / g")

```


```{r echo=FALSE, eval=T,message=FALSE, warning=FALSE, fig.width = 7.2, fig.height= 3,fig.cap='Distance to real changepoint in biomass per total number of samples analyzed, following (a) random sampling, (b) regular sampling, and (c) iterative sampling. Total number of samples was set between 5 and 30, out of the 74 initial time series.   \\label{fig:case_study_number_sample_biomass}'}

myoutput <- read.table(paste0(getwd(),"/Output/output_changepoint_varese_biomass.txt"))
myoutput$method <- factor(myoutput$method, levels=c('Random', 'Regular', 'Iterative'))
myoutput$diff_real <- abs(myoutput$diff_real)


# Plot
p1 <-
  ggplot(myoutput[myoutput$target_cpt==1 & myoutput$n2_init == 5,], aes(final_n,diff_real)) + 
  geom_hline(aes(yintercept=0), col=adjustcolor("black", alpha.f = .4)) + 
  geom_point(alpha = .3) +
  facet_wrap(~method,
             labeller = label_glue('{.l}. {method} sampling ')) + 
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        strip.background = element_rect(colour="transparent", fill="transparent"),
        strip.text.x = element_text(angle = 0, hjust = 0)) +
  labs(x="Total number of samples analyzed", y="Distance to real changepoint") 


p1


```






\clearpage

# References